<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Airflow on GoniGoni!</title>
    <link>/tags/airflow/</link>
    <description>Recent content in Airflow on GoniGoni!</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ko-kr</language>
    <lastBuildDate>Mon, 01 Mar 2021 17:00:00 +0900</lastBuildDate><atom:link href="/tags/airflow/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>데이터 분석 워크플로우를 처음부터 만들어 보기</title>
      <link>/posts/data-workflow-from-scratch/</link>
      <pubDate>Mon, 01 Mar 2021 17:00:00 +0900</pubDate>
      
      <guid>/posts/data-workflow-from-scratch/</guid>
      <description>지난 달에는 데이터 수집을 위한 환경 구성을 처음부터 만들어 보았습니다. 어느 정도 초기 환경을 구축했다고 판단해서, 이번에는 데이터 분석을 위한 워크플로우를 처음부터 만들어 보는 과정을 기록해 보려고 합니다.
이번에는 Apache Airflow를 이용해서 데이터 분석 작업을 위한 환경을 구축해 보았습니다. 여러 곳에서 Airflow를 사용하는 사례를 듣다 보니, Airflow를 한번 써 봐야겠다고 생각했습니다. 최근에는 AWS에서도 Managed Workflows for Apache Airflow라는 관리형 서비스를 제공하고 있고, GCP에서는 Cloud Composer라는 이름으로 관리형 서비스를 제공하고 있습니다.</description>
    </item>
    
  </channel>
</rss>
