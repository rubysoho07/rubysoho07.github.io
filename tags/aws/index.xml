<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>AWS on GoniGoni!</title>
    <link>/tags/aws/</link>
    <description>Recent content in AWS on GoniGoni!</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ko-kr</language>
    <lastBuildDate>Tue, 22 Oct 2019 21:02:00 +0900</lastBuildDate>
    
	<atom:link href="/tags/aws/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>AWS SAM을 사용하면서 느꼈던 것들</title>
      <link>/posts/retrospect-aws-sam/</link>
      <pubDate>Tue, 22 Oct 2019 21:02:00 +0900</pubDate>
      
      <guid>/posts/retrospect-aws-sam/</guid>
      <description>왜 SAM을 사용하게 되었나? 시스템 내부에서 관리하는 Lambda 함수들이 늘어나면서, 이를 관리할 방법을 찾아야 했다. 기존에는 Apex를 Lambda 함수 배포에 이용했지만, 뭔가 자동화된 방법을 찾고 싶었다.
그래서 Serverless Framework, Terraform, SAM과 같은 도구들을 검토해 봤다. 그러다가 SAM을 최종적으로 선택했는데, 이유는 다음과 같다.
  Serverless Framework는 다양한 클라우드 벤더를 지원하지만, 다른 AWS 서비스를 연동하는 데 제약이 있지 않을까? 하는 막연한 생각이 들었다. (잘 찾아보니 내가 원하는 것들은 구현 가능할 것 같더라.</description>
    </item>
    
    <item>
      <title>Hortonworks Sandbox를 AWS에서 사용하기</title>
      <link>/posts/hortonworks-sandbox-on-aws/</link>
      <pubDate>Wed, 16 Oct 2019 21:05:00 +0900</pubDate>
      
      <guid>/posts/hortonworks-sandbox-on-aws/</guid>
      <description>들어가며 최근에 &amp;lsquo;하둡과 스파크를 활용한 실용 데이터 과학&amp;rsquo;이라는 책을 읽고 따라해 보고 있다. 이 책에서는 실습을 위해 호튼웍스(Hortonworks)의 Sandbox 이미지를 사용해 보기를 권장하고 있다. 그런데 설치 방법을 찾다 보니, 권장 사양이 높은 것 같다는 생각이 들었다. 이 이미지를 VirtualBox에서 사용할 때, 메모리 용량이 8GB로 설정되어 있었다. 그런데 지금 내가 쓰고 있는 노트북의 메모리 용량이 8GB라 좀 어려울 것 같았다. 그래서 AWS에 이 이미지를 올려보게 되었다.
(주의: 이 글에서 설명하는 내용은 AWS의 Free Tier 범위를 넘어가므로 사용한 만큼 요금이 부과됩니다.</description>
    </item>
    
    <item>
      <title>EC2에 Bitnami MongoDB 이미지 올리기</title>
      <link>/posts/bitnami-mongodb/</link>
      <pubDate>Sat, 16 Feb 2019 22:30:00 +0900</pubDate>
      
      <guid>/posts/bitnami-mongodb/</guid>
      <description>최근에 AWS에서 MongoDB와 호환되는 DocumentDB를 출시했지만, 아직 서울 리전에서는 사용할 수 없다.
(2019년 5월에 서울 리전에 출시되었습니다. 링크한 글을 확인해 주세요~)
그렇지만 필요에 따라 MongoDB를 쓸 일이 있을 것이다. AWS에서 Bitnami의 이미지를 활용해서 EC2에 MongoDB를 올려보고, 시험 삼아 데이터를 넣어보자.
EC2 설정 EC2 인스턴스를 생성하기 위해 AWS의 EC2 콘솔로 들어간다. 아래 스크린샷과 같은 화면이 나오면, &amp;lsquo;인스턴스 시작&#39;을 누른다.
  그리고 검색어에서 MongoDB를 입력하고, 왼쪽에서 AWS Marketplace를 누른다.
  스크롤을 아래로 내리다 보면, &amp;lsquo;MongoDB Certified by Bitnami&#39;가 있다.</description>
    </item>
    
    <item>
      <title>S3 버킷의 객체가 1,000개를 넘을 때 객체 목록 조회하기</title>
      <link>/posts/list-over-1000-files-from-s3/</link>
      <pubDate>Thu, 29 Nov 2018 00:38:00 +0900</pubDate>
      
      <guid>/posts/list-over-1000-files-from-s3/</guid>
      <description>S3 버킷에는 여러 파일들을 저장할 수 있다. 그런데, 버킷에 저장된 파일의 목록을 보고 싶은 경우가 있을 것이다. 하지만, AWS의 Python SDK인 Boto3에서 list_objects()나 list_objects_v2() 함수를 이용하면 최대 1,000개까지의 object만 가져올 수 있다. [참고] (근본적으로는 AWS의 API가 최대 1,000개까지의 object만 가져오도록 구현되어 있다. - [참고])
이런 문제를 해결하기 위해, 다음과 같이 Paginator를 이용해 보자.
Paginator 이용하기 get_paginator()로 Paginator 가져오기 기본적으로 S3를 담당할 클라이언트를 생성한 뒤, get_paginator()로 Paginator를 가져온다. 여기서는 하나의 버킷에서 object들을 가져오기 위해 list_objects_v2를 이용한다.</description>
    </item>
    
    <item>
      <title>Python으로 Step Functions 활동 만들기</title>
      <link>/posts/step-function-with-python/</link>
      <pubDate>Thu, 04 Oct 2018 23:21:00 +0900</pubDate>
      
      <guid>/posts/step-function-with-python/</guid>
      <description>AWS에는 Step Functions라는 서비스가 있다. 여러 개의 활동(activity)를 조합해서 순서대로 또는 반복적으로 원하는 작업을 실행할 수 있도록 해 주는 서비스이다.
일반적으로는 여러 개의 Lambda 함수를 연결해서 사용하는 경우가 많다. 하지만 Lambda 함수의 실행 시간이 5분을 넘어가면, 다른 방법을 고려해야 한다. 이럴 때 활동을 생성하고 이를 수행하는 코드를 작성하면, 오래 걸리는 작업도 Step Functions로 이용할 수 있다.
활동(Activity) 만들기  Step Functions 콘솔의 왼쪽 메뉴에서 활동을 클릭한다. 화면이 바뀌면 우측의 활동 생성을 클릭하여 새로운 활동을 만든다.</description>
    </item>
    
    <item>
      <title>RDS MySQL에서 일반/느린 쿼리 로그 찍기</title>
      <link>/posts/logging-rds/</link>
      <pubDate>Wed, 03 Oct 2018 14:24:00 +0900</pubDate>
      
      <guid>/posts/logging-rds/</guid>
      <description>RDS MySQL을 이용하면, 아래와 같이 CloudWatch에 일반/감사/느린 쿼리 로그를 찍도록 설정할 수 있다.
그리고 RDS 콘솔에 들어가면 로그 파일을 볼 수 있는데, 일반 로그나 느린 쿼리 로그를 찾을 수 없었다. 그래서 CloudWatch Logs를 찾아봤지만, 역시 로그가 없었다.
그 이유를 찾아 보니, 파라미터 그룹에 로그 관련 설정을 하지 않은 것이 원인이었다.
다음과 같이 설정하면 된다.
먼저, RDS 콘솔에서 파라미터 그룹 메뉴를 클릭한다. 쓰던 파라미터 그룹이 있다면, 그 파라미터 그룹을 클릭하고, 새로 생성해야 한다면 파라미터 그룹 생성을 클릭해서 파라미터 그룹을 만든다.</description>
    </item>
    
    <item>
      <title>AWS Lambda에서 별칭(alias)으로 함수 버전 구분하기</title>
      <link>/posts/check-lambda-version/</link>
      <pubDate>Tue, 02 Oct 2018 23:16:00 +0900</pubDate>
      
      <guid>/posts/check-lambda-version/</guid>
      <description>test라는 함수가 있고, dev, release라는 별칭(alias)이 존재한다고 하자. 그리고 모든 별칭은 동일한 버전을 가리킨다고 하자.
이 경우 context 객체의 invoked_function_arn은 어떻게 달라지는지 보자. 테스트를 위해, 다음과 같이 파이썬으로 함수를 작성하였다.
import jsondef lambda_handler(event, context): print(context.invoked_function_arn)return &amp;#34;Success&amp;#34;그리고 CloudWatch에 기록된 로그를 보자.
dev인 경우
START RequestId: 2dce0b80-5fb4-11e8-b5b7-41e11422a67a Version: 1arn:aws:lambda:ap-northeast-2:256724228018:function:test:devEND RequestId: 2dce0b80-5fb4-11e8-b5b7-41e11422a67aREPORT RequestId: 2dce0b80-5fb4-11e8-b5b7-41e11422a67a Duration: 1.56 ms Billed Duration: 100 ms Memory Size: 128 MB Max Memory Used: 22 MBrelease인 경우</description>
    </item>
    
  </channel>
</rss>